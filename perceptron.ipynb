{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação Continuada (AC2) - Perceptron\n",
    "\n",
    "Nesse notebook, iremos ver como aplicar o método Perceptron na nossa base de dados que foi processada no notebook `train_data.ipynb`.\n",
    "\n",
    "Para começar então, vamos importar o notebook `train_data.ipynb` que irá conter tudo que precisamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Agora, com os dados separados, vamos começar o treinamento usando o método Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, importamos o método que iremos usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, podemos definir algumas variáveis para customizar o comportamento do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_interations = 100 # vai controlar a quantidade de interações que será realizada no modelo, também chamado de epochs\n",
    "learning_rate = 0.1 # a constante que representa a taxa de aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, criamos o nosso modelo da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(max_iter=n_interations, eta0=learning_rate, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E ai, já podemos começar o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(eta0=0.1, max_iter=100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.fit(train_data.x_train, train_data.y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E com o modelo treinado, podemos começar a ver as métricas de acurácia do nosso modelo tentando predizer os valores de teste que separamos na etapa anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = perceptron.predict(train_data.x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os valores que foram classificados acima, podemos ver qual foi a sua performance usando o `sklearn` da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.86      0.92      1352\n",
      "        spam       0.49      0.92      0.64       196\n",
      "\n",
      "    accuracy                           0.87      1548\n",
      "   macro avg       0.74      0.89      0.78      1548\n",
      "weighted avg       0.92      0.87      0.89      1548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = sklearn.metrics.classification_report(train_data.y_test, y_pred, target_names=['ham', 'spam'])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a tabela acima, podemos tirar algumas conclusões como: \n",
    "\n",
    "A precisão para identificar mensagens verdadeiras é maior do que a precisão do que identificar mensagens de spam. E isso não necessariamente é ruim porque é melhor errar mais mensagens de spam do que mensagens verdadeiras.\n",
    "\n",
    "Dessa forma, no pior dos casos ainda vemos o spam e ignoramos mas com a mensagem real indo parar no spam, é mais dificil de ir lá olhar.\n",
    "\n",
    "E além disso, podemos checar a nossa acurácia com mais precisão tanto dos valores de teste quanto dos valores de treino da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia sobre os valores de teste:  0.8701550387596899\n",
      "Acurácia sobre os valores de treino:  0.8775284012191743\n"
     ]
    }
   ],
   "source": [
    "accuracyTest = train_data.accuracy_score(train_data.y_test, perceptron.predict(train_data.x_test))\n",
    "accuracyTrain = train_data.accuracy_score(train_data.y_train, perceptron.predict(train_data.x_train))\n",
    "\n",
    "print(\"Acurácia sobre os valores de teste: \", accuracyTest)\n",
    "print(\"Acurácia sobre os valores de treino: \", accuracyTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E aqui vemos, temos, assim como mostrado no relatório anterior, certa de 88% e 87% de acurácia sobre os valores de teste e de treino, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Apesar de eu não entender tão bem como funciona a validação cruzada, eu quis trazer nesses métodos para ter um pequena noção de como a ordem dos dados de treinamento influenciam o nosso modelo.\n",
    "\n",
    "Dessa forma, o cross-validation permite que a gente separe em partições os nossos dados, e eles por consequencia, serão usados para treinar várias vezes o modelo e assim podemos obter as métrica de acurácia de cada vez que foi treinado o modelo.\n",
    "\n",
    "Com essas métricas, podemos verificar se a mudança na ordem dos dados tem uma mudança significativa na acurácia do nosso modelo.\n",
    "\n",
    "Vamos começar então com a importação das bibliotecas que iremos usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, vamos criar algumas variáveis para configurarmos como será a cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5 # o número de partições\n",
    "test_size = 0.3 # a porcentagem que será usada para teste, o restante é usada no treino\n",
    "cv = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=0) # define a função que irá realizar o rearranjo dos dados de treino e como será divido os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E assim, podemos agora chamar a função `cross_val_score` que irá nos retornar a acurácia, assim como, o desvio da acurácia que nos diz quanto a ordem os dados está influenciando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92 acurácia com o desvio de 0.02\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(perceptron, train_data.x, train_data.y, cv=cv)\n",
    "\n",
    "print(\"%0.2f acurácia com o desvio de %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É interessante ver que agora a acurácia do modelo saiu de 87% para 92%, com um erro de 0.02. \n",
    "\n",
    "Isso foi uma melhoria muito boa que foi dado simplesmente pela forma na qual separamos os nossos dados.\n",
    "\n",
    "E professor, se você chegou até aqui, seria interessante ver mais sobre cross-validation nas aulas."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "177401c68bf2cebd86e5b16616fdddb5ae8a22ec2666d9ac189b12bd387b0870"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
