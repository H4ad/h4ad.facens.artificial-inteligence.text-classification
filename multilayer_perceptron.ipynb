{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação Continuada (AC2) - Multi-Layer Perceptron\n",
    "\n",
    "Nesse notebook, iremos ver como aplicar o método Multi-Layer Perceptron na nossa base de dados que foi processada no notebook `train_data.ipynb`.\n",
    "\n",
    "Para começar então, vamos importar o notebook `train_data.ipynb` que irá conter tudo que precisamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from train_data.ipynb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category                 Message\n",
       "count      5572                    5572\n",
       "unique        2                    5157\n",
       "top         ham  Sorry, I'll call later\n",
       "freq       4825                      30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape antes de remover os dados.\n",
      "(5572, 2)\n",
      "\n",
      "Shape após remover os dados.\n",
      "(5157, 2)\n",
      "\n",
      "Quantidade de itens removidos: 415\n",
      "Um dos textos antes do processamento:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I sent you  &lt;#&gt;  bucks'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O mesmo texto, só que agora processado:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sent you bucks'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algumas palavras que iremos usar para montar o nosso vocabulário:\n",
      "['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'great', 'world', 'la', 'buffet', 'cine', 'there', 'got', 'amore', 'wat']\n",
      "Tamanho do Vocabulario:  3632\n",
      "[ 0.17063391 -0.12037469 -0.08291905  0.15739855  0.2682453  -0.33576694\n",
      "  0.19767639  0.6196071  -0.18136293  0.23382549 -0.22981985 -0.37787122\n",
      "  0.10857213  0.19396725 -0.09153517 -0.33911714 -0.073304   -0.0172643\n",
      "  0.02148758 -0.48436213  0.22057416 -0.2971259  -0.1620915  -0.11847548\n",
      "  0.08773892 -0.22823392 -0.04131408 -0.14172244 -0.32659385  0.14238487\n",
      "  0.39600694  0.01346408  0.1605743  -0.08500466 -0.07830664  0.22776961\n",
      "  0.27652663 -0.13253841 -0.06927069 -0.49206936 -0.32059664 -0.08952628\n",
      "  0.00514935  0.11230633  0.49850705 -0.14280826 -0.21242063 -0.0868315\n",
      "  0.155477    0.20335472  0.00258972 -0.1425103  -0.2185309  -0.2870042\n",
      "  0.08256965 -0.09182009 -0.00823445 -0.30026847 -0.30620897  0.13255653\n",
      " -0.00526275  0.04798831  0.00124297 -0.07060679 -0.59850734  0.14069398\n",
      "  0.01551399  0.6426611  -0.29788622  0.48766527 -0.02309377  0.01035961\n",
      "  0.34066546  0.03720865  0.11031528  0.19557902  0.27253067 -0.23934379\n",
      " -0.4848397  -0.06057859 -0.2081396  -0.07300289 -0.47031105  0.6267135\n",
      " -0.26443753 -0.03464472  0.0265474   0.30924413  0.03952838 -0.20418559\n",
      "  0.20562522  0.3458381   0.22653441  0.40148053  0.5982367   0.33741108\n",
      "  0.16310893 -0.3571532   0.28417388  0.22529149 -0.49230537  0.4894059\n",
      "  0.18176776 -0.17826173 -0.31647524 -0.3560979   0.12711386  0.45493\n",
      " -0.2420405  -0.40583017 -0.04815305 -0.44617307 -0.0932746  -0.07871703\n",
      "  0.14902647 -0.08773965  0.27006248 -0.60902935 -0.24463381 -0.28000444\n",
      "  0.01953072  0.32654867  0.20613201 -0.28883028 -0.26631084  0.30935562\n",
      " -0.21122906 -0.15371233 -0.18483777  0.04906932  0.24096824  0.13439131\n",
      " -0.22118647 -0.22078812 -0.1649197   0.4318237  -0.2105619  -0.3842349\n",
      " -0.12487807 -0.4075246   0.26892006 -0.44960007 -0.08777665 -0.08656753\n",
      "  0.03940301 -0.14260525 -0.18495525  0.11778299  0.00692094  0.04051721\n",
      "  0.14202979 -0.34850487  0.0644933   0.14638981 -0.67742944  0.49077997\n",
      "  0.31726524  0.36923662 -0.05445429  0.14976442  0.23124924  0.2033152\n",
      " -0.09177703 -0.07767732 -0.00464241  0.1705844   0.13356663 -0.25562486\n",
      " -0.21858354  0.10358366 -0.2941077   0.19396268 -0.02922731 -0.21072821\n",
      "  0.17400499  0.20192061 -0.27911645  0.13979034  0.14264679  0.1822279\n",
      " -0.0143114   0.02452875  0.03341857  0.0560823   0.10539464  0.04267456\n",
      " -0.05702584  0.15164414  0.4073382   0.07466398  0.38861358  0.04481528\n",
      " -0.22637708 -0.22339728  0.20947082  0.2731708   0.25613257 -0.42063203\n",
      " -0.02437726 -0.12007114]\n",
      "[('claim', 0.9993543028831482), ('prize', 0.9991828203201294), ('cash', 0.9990876913070679), ('guaranteed', 0.998891294002533), ('or', 0.998778760433197), ('stop', 0.9987028241157532), ('txt', 0.9986814260482788), ('<NUMBER>p', 0.9986782073974609), ('reply', 0.9986584186553955), ('free', 0.9984568953514099)]\n",
      "Testando com uma frase qualquer\n",
      "[ 9.53830630e-02 -7.74412081e-02 -6.20437488e-02  7.38312230e-02\n",
      "  1.92664981e-01 -2.03680962e-01  7.19013438e-02  3.57850850e-01\n",
      " -1.22605905e-01  1.09593287e-01 -1.59981862e-01 -2.02064529e-01\n",
      "  7.10743293e-02  1.29528105e-01 -4.32864092e-02 -1.83668330e-01\n",
      " -5.90214990e-02 -5.18359337e-03  5.95581718e-03 -2.71645248e-01\n",
      "  1.15404360e-01 -1.44072101e-01 -6.74099103e-02 -8.59812051e-02\n",
      "  5.50726429e-02 -1.28521562e-01 -3.06471828e-02 -8.42566490e-02\n",
      " -1.87790826e-01  1.04848281e-01  2.24849761e-01  3.16365995e-03\n",
      "  6.96922839e-02 -2.31092907e-02 -3.57426703e-02  1.30925670e-01\n",
      "  1.28958210e-01 -7.94975460e-02 -3.59896496e-02 -3.08882535e-01\n",
      " -1.57889545e-01 -2.10600253e-02  9.75942705e-03  6.78196102e-02\n",
      "  3.04929644e-01 -5.23629487e-02 -1.20431133e-01 -8.20546821e-02\n",
      "  9.33174938e-02  1.05051346e-01  1.70436241e-02 -1.02547511e-01\n",
      " -1.22910917e-01 -1.55924782e-01  3.93552445e-02 -3.43787223e-02\n",
      " -1.91213191e-02 -1.62061930e-01 -1.73123896e-01  6.04051128e-02\n",
      "  2.96262582e-03  2.17235629e-02 -1.20576797e-02 -3.73903401e-02\n",
      " -3.33181143e-01  9.32551324e-02  1.82537585e-02  3.53262722e-01\n",
      " -1.83194712e-01  2.94471800e-01 -2.53888071e-02  9.26976278e-03\n",
      "  2.04131559e-01  1.37175499e-02  6.66518658e-02  1.06477015e-01\n",
      "  1.58569604e-01 -1.65532976e-01 -3.13792288e-01 -9.28117242e-03\n",
      " -1.33360192e-01 -3.44080701e-02 -2.65622318e-01  3.78088564e-01\n",
      " -1.39580652e-01 -3.36844549e-02 -1.84398057e-04  1.80929095e-01\n",
      "  1.90581642e-02 -1.26078248e-01  1.26070157e-01  2.03837827e-01\n",
      "  1.33181438e-01  2.47503549e-01  3.42528462e-01  1.92012489e-01\n",
      "  1.09754361e-01 -1.85075983e-01  1.66979626e-01  1.39953882e-01\n",
      " -2.75012702e-01  2.95122623e-01  9.50822607e-02 -9.74451602e-02\n",
      " -1.96086779e-01 -2.09640384e-01  9.10927579e-02  2.84907281e-01\n",
      " -1.43401042e-01 -2.38098189e-01 -3.69342044e-02 -2.58426189e-01\n",
      " -5.98565079e-02 -6.07324541e-02  7.28579164e-02 -7.58589134e-02\n",
      "  1.49107695e-01 -3.80917370e-01 -1.43910408e-01 -1.64165601e-01\n",
      " -3.13607999e-03  1.93180487e-01  1.04398698e-01 -1.42655328e-01\n",
      " -1.62134662e-01  1.63687527e-01 -1.01567119e-01 -1.22966953e-01\n",
      " -9.64907184e-02 -1.75211132e-02  1.38607174e-01  6.13447949e-02\n",
      " -1.15135260e-01 -1.20491415e-01 -7.73537979e-02  2.36850888e-01\n",
      " -1.22016191e-01 -2.17244118e-01 -1.01823814e-01 -2.51903415e-01\n",
      "  1.52753651e-01 -2.55056381e-01 -5.46575189e-02 -7.01980069e-02\n",
      " -3.20650032e-03 -6.70015663e-02 -1.26368061e-01  7.56869391e-02\n",
      "  1.03612216e-02  2.19458714e-02  7.23995715e-02 -2.02566639e-01\n",
      "  3.29190269e-02  8.66610035e-02 -3.84153366e-01  2.87979931e-01\n",
      "  1.76481768e-01  2.04700693e-01 -3.92122567e-02  9.89945307e-02\n",
      "  1.49362549e-01  9.78164524e-02 -5.17309941e-02 -3.86500694e-02\n",
      " -1.35636167e-03  1.05810329e-01  7.85220042e-02 -1.49448276e-01\n",
      " -1.61145702e-01  2.98790541e-02 -1.66994214e-01  1.09840043e-01\n",
      " -1.28289675e-02 -1.34821340e-01  9.44513977e-02  1.32577464e-01\n",
      " -1.64840609e-01  9.53660831e-02  6.98557422e-02  1.20943658e-01\n",
      " -1.11651244e-02  1.68735068e-02 -1.12782316e-02  4.14032117e-02\n",
      "  8.81541371e-02  3.01990639e-02 -2.31039990e-02  1.31678745e-01\n",
      "  2.35870048e-01  3.39745432e-02  2.25148410e-01  3.17313410e-02\n",
      " -1.31648153e-01 -9.51168165e-02  1.10532008e-01  1.50381193e-01\n",
      "  1.49294719e-01 -2.51148164e-01  1.78623456e-03 -7.41711855e-02]\n",
      "Shape do vetor de classe:  (5157,)\n",
      "Shape do vetor de valores:  (5157, 200)\n",
      "Qntd. de amostras de treino:  3609\n",
      "Qntd de amostras de teste:  1548\n",
      "\n",
      "Qtd. de dados de cada classe (treinamento)\n",
      "\tClasse ham:  3164\n",
      "\tClasse spam:  445\n",
      "\n",
      "Qtd. de dados de cada classe (teste)\n",
      "\tClasse ham:  1352\n",
      "\tClasse spam:  196\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de começarmos o treinamento realmente, precisamos só mapear as nossas classes \"spam\" e \"ham\" para valores númericos para que a rede neural possa trabalhar com isso.\n",
    "\n",
    "Se caso enviassemos um texto, \"spam\", ele iria mandar uma exceção durante a execução.\n",
    "\n",
    "Além disso, também iremos preparar os valores de treino e teste e mapear eles para uma escala próximo de zero, com isso, melhoramos a precisão do nosso modelo.\n",
    "\n",
    "Dessa forma, iremos criar duas funções para realizar essas transformações:\n",
    "\n",
    "- `prepare_classes`: Prepara as classes (y).\n",
    "- `prepare_values`: Prepara os valores (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_classes(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\n",
    "\treturn y_train_enc, y_test_enc\n",
    "\n",
    "def prepare_values(x_train, x_test):\n",
    "\tsc_X = StandardScaler()\n",
    "\n",
    "\tx_train_scaled = sc_X.fit_transform(x_train)\n",
    "\tx_test_scaled = sc_X.transform(x_test)\n",
    "\n",
    "\treturn x_train_scaled, x_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as funções definidas, vamos agora processar os nossos valores de teste e treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data, y_test_data = prepare_classes(train_data.y_train, train_data.y_test)\n",
    "x_train_data, x_test_data = prepare_values(train_data.x_train, train_data.x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, podemos definir algumas variáveis para customizar o comportamento do nosso modelo.\n",
    "\n",
    "- `hidden_layer_sizes`: Cada número representa o número de neuronios que será criado para a camada e cada item no vetor é uma camada. No exemplo abaixo, estaremos montando uma rede neural com 2 camadas, com 5 e 2 neuronios.\n",
    "- `max_iter`: o número máximo de interações (também chamado de epochs)\n",
    "- `tol`: o valor mínimo de melhoria após cada interação, se não melhorar ao menos isso, ele para a execução bem antes.\n",
    "- `solver`: a estratégia que será usada para resolver o problema, abaixo, o valor será `lbfgs` (método quasi-newton). Segundo a [documentação do modelo](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#), para datasets menores, esse é um método recomendado e trás bons resultados.\n",
    "- `activation`: a função de ativação, no caso, será a `relu`, que você pode ver mais informações [clicando aqui](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = (5, 2)\n",
    "max_iter = 2000\n",
    "tol = 0.000001\n",
    "solver = \"lbfgs\"\n",
    "activation = \"relu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, criamos o nosso modelo da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlPerceptron = MLPClassifier(\n",
    "  hidden_layer_sizes=hidden_layer_sizes,\n",
    "  max_iter=max_iter,\n",
    "  tol=tol,\n",
    "  solver=solver,\n",
    "  activation=activation,\n",
    "  random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E ai, já podemos começar o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(5, 2), max_iter=2000, random_state=0,\n",
       "              solver='lbfgs', tol=1e-06)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlPerceptron.fit(x_train_data, y_train_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E com o modelo treinado, podemos começar a ver as métricas de acurácia do nosso modelo tentando predizer os valores de teste que separamos na etapa anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlPerceptron.predict(x_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os valores que foram classificados acima, podemos ver qual foi a sua performance usando o `sklearn` da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.98      0.98      0.98      1352\n",
      "        Spam       0.84      0.85      0.85       196\n",
      "\n",
      "    accuracy                           0.96      1548\n",
      "   macro avg       0.91      0.91      0.91      1548\n",
      "weighted avg       0.96      0.96      0.96      1548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_test_named = y_test_data.copy().astype(str)\n",
    "\n",
    "y_test_named[y_test_named == \"0\"] = \"Ham\"\n",
    "y_test_named[y_test_named == \"1\"] = \"Spam\"\n",
    "\n",
    "y_pred_named = y_pred.copy().astype(str)\n",
    "y_pred_named[y_pred_named == \"0\"] = \"Ham\"\n",
    "y_pred_named[y_pred_named == \"1\"] = \"Spam\"\n",
    "\n",
    "results = classification_report(y_test_named, y_pred_named)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a tabela acima, podemos tirar algumas conclusões como: \n",
    "\n",
    "E em comparação com os outros modelos, usando uma rede neural nós tivemos uma precisão maior na classe de Spam, assim como, uma acurácia muito boa também para o modelo como um todo.\n",
    "\n",
    "Além disso, podemos checar a nossa acurácia com mais precisão tanto dos valores de teste quanto dos valores de treino da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia sobre os valores de teste:  0.9612403100775194\n",
      "Acurácia sobre os valores de treino:  1.0\n"
     ]
    }
   ],
   "source": [
    "accuracyTest = train_data.accuracy_score(y_test_data, mlPerceptron.predict(x_test_data))\n",
    "accuracyTrain = train_data.accuracy_score(y_train_data, mlPerceptron.predict(x_train_data))\n",
    "\n",
    "print(\"Acurácia sobre os valores de teste: \", accuracyTest)\n",
    "print(\"Acurácia sobre os valores de treino: \", accuracyTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E aqui vemos, temos, assim como mostrado no relatório anterior, certa de 96% e 100% de acurácia sobre os valores de teste e de treino, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Apesar de eu não entender tão bem como funciona a validação cruzada, eu quis trazer nesses métodos para ter um pequena noção de como a ordem dos dados de treinamento influenciam o nosso modelo.\n",
    "\n",
    "Dessa forma, o cross-validation permite que a gente separe em partições os nossos dados, e eles por consequencia, serão usados para treinar várias vezes o modelo e assim podemos obter as métrica de acurácia de cada vez que foi treinado o modelo.\n",
    "\n",
    "Com essas métricas, podemos verificar se a mudança na ordem dos dados tem uma mudança significativa na acurácia do nosso modelo.\n",
    "\n",
    "Vamos começar então com a importação das bibliotecas que iremos usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, vamos criar algumas variáveis para configurarmos como será a cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5 # o número de partições\n",
    "test_size = 0.3 # a porcentagem que será usada para teste, o restante é usada no treino\n",
    "cv = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=0) # define a função que irá realizar o rearranjo dos dados de treino e como será divido os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E assim, podemos agora chamar a função `cross_val_score` que irá nos retornar a acurácia, assim como, o desvio da acurácia que nos diz quanto a ordem os dados está influenciando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96 acurácia com o desvio de 0.01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.concatenate([x_train_data, x_test_data], axis=0)\n",
    "y = np.concatenate([y_train_data, y_test_data], axis=0)\n",
    "\n",
    "scores = cross_val_score(mlPerceptron, x, y, cv=cv)\n",
    "\n",
    "print(\"%0.2f acurácia com o desvio de %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É interessante ver que agora a acurácia do modelo nem mudou de lugar, continuou nos 96% de antes.\n",
    "\n",
    "Se comparado ao realizar isso com outros métodos, podemos perceber então que a ordem dos dados não influencia tanto a rede neural quanto afeta os outros métodos."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "177401c68bf2cebd86e5b16616fdddb5ae8a22ec2666d9ac189b12bd387b0870"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
